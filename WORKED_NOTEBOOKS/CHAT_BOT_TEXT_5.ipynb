{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\")\n",
    "from langchain.schema import Document\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LOADING THE SAVED CHUNKS AND THE CHROMA VECTOR DATABASE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunks(filename=\"preprocessed_chunks.json\"):\n",
    "    with open(filename, 'r') as f:\n",
    "        chunk_dicts = json.load(f)\n",
    "    return [Document(page_content=c[\"page_content\"], metadata=c[\"metadata\"]) for c in chunk_dicts]\n",
    "\n",
    "# Load chunks instead of reprocessing PDF\n",
    "chunks = load_chunks()\n",
    "\n",
    "# Load the stored vector database\n",
    "vectorstore = Chroma(persist_directory=\"./chroma_db_pedition\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>USING BOTH VECTOR SIMILARITY AND KEYWORD SIMILARITY</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "# vector retriever\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Keyword retriever (BM25)\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Hybrid ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.7, 0.3]  # tune if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>HYBRID APPROACH OF USING HYBRID RETRIEVAL APPROACH FOLLOWED BY RE-RANKING</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anandhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load cross-encoder model\n",
    "# rerank_model_name = \"BAAI/bge-reranker-large\" # USE THIS IF NEEDED A PRECISE RESULT\n",
    "rerank_model_name = \"BAAI/bge-reranker-base\"  # USE THIS IF NEEDED A FASTER RESULT\n",
    "tokenizer = AutoTokenizer.from_pretrained(rerank_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(rerank_model_name)\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from langchain.schema import Document\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def rerank_chunks(query, chunks, top_k=3):\n",
    "    # Split paragraphs into sentences while maintaining metadata\n",
    "    sentences = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            chunk_sentences = sent_tokenize(chunk.page_content)\n",
    "        except:\n",
    "            # Fallback for simple sentence splitting if NLTK fails\n",
    "            chunk_sentences = chunk.page_content.split('. ')\n",
    "        \n",
    "        for sent in chunk_sentences:\n",
    "            sentences.append(Document(\n",
    "                page_content=sent.strip(),\n",
    "                metadata=chunk.metadata  # Preserve original metadata\n",
    "            ))\n",
    "\n",
    "    # Create query-sentence pairs for scoring\n",
    "    pairs = [[query, doc.page_content] for doc in sentences]\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, \n",
    "                      return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(**inputs).logits.view(-1).float()\n",
    "\n",
    "    # Sort sentences by their relevance scores\n",
    "    sorted_indices = scores.argsort(descending=True)\n",
    "    top_sentences = [sentences[i] for i in sorted_indices[:top_k]]\n",
    "    top_scores = scores[sorted_indices[:top_k]].numpy()\n",
    "\n",
    "    return top_sentences, top_scores\n",
    "\n",
    "\n",
    "def calculate_confidence(scores):\n",
    "    \"\"\"Takes the scores from `rerank_chunks` and applies sigmoid to get a confidence score.\"\"\"\n",
    "    probabilities = torch.sigmoid(torch.tensor(scores)).numpy()\n",
    "    return float(np.max(probabilities))  # Return the highest confidence score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LOADING HUGGINGFACE MODELS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import HuggingFaceHub\n",
    "# from AI_GATEWAYS import huggingface_api_key\n",
    "\n",
    "# llm = HuggingFaceHub(\n",
    "#     repo_id=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "#     model_kwargs={\"temperature\": 0.2, \"max_length\": 1024},\n",
    "#     huggingfacehub_api_token=huggingface_api_key\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from AI_GATEWAYS import huggingface_api_key\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"deepseek-ai/DeepSeek-R1\",\n",
    "    model_kwargs={\"temperature\": 0.2, \"max_length\": 1024},\n",
    "    huggingfacehub_api_token=huggingface_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LLM IMPLEMENTATION USING MEMORY AND THRESHHOLD</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# Create memory that retains last 3 exchanges\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=10,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful AI assistant. Answer the user's question based on the conversation history and the provided Odyssey context. \n",
    "\n",
    "    ### Chat History:\n",
    "    {chat_history}\n",
    "\n",
    "    ### Context:\n",
    "    {context}\n",
    "\n",
    "    ### Question: \n",
    "    {question}\n",
    "\n",
    "    ### Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": lambda x: x[\"chunks\"], \n",
    "     \"question\": lambda x: x[\"question\"],\n",
    "     \"chat_history\": lambda x: x[\"chat_history\"]}\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chunks(chunks):\n",
    "    return \"\\n\\n\".join([f\"Page {c.metadata['page']}: {c.page_content}\" for c in chunks])\n",
    "\n",
    "\n",
    "\n",
    "def get_threshold_response():\n",
    "    return \"I'm not entirely confident about this answer. Would you like to rephrase or ask about another topic?\"\n",
    "\n",
    "\n",
    "\n",
    "# Modified ask_question function with confidence scoring\n",
    "def ask_question(question, confidence_threshold=0.65):\n",
    "    # Retrieve context\n",
    "    initial_chunks = ensemble_retriever.get_relevant_documents(question)\n",
    "    final_chunks, relevance_scores = rerank_chunks(question, initial_chunks, top_k=3)\n",
    "    \n",
    "    # Calculate confidence\n",
    "    confidence = calculate_confidence(relevance_scores)\n",
    "    \n",
    "    # Generate answer\n",
    "    raw_answer = qa_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"chunks\": format_chunks(final_chunks),\n",
    "        \"chat_history\": memory.load_memory_variables({})[\"chat_history\"]\n",
    "    })\n",
    "\n",
    "    # Extract everything after \"### Answer:\"\n",
    "    answer = raw_answer.split(\"### Answer:\")[-1].strip()\n",
    "    \n",
    "    # Store interaction in memory\n",
    "    memory.save_context({\"question\": question}, {\"answer\": answer})\n",
    "    \n",
    "    # Add confidence and sources\n",
    "    sources = list(set(c.metadata[\"page\"] for c in final_chunks))\n",
    "    response = f\"{answer}\\n\\nConfidence: {confidence:.0%}\\nSources: Pages {', '.join(map(str, sources))}\"\n",
    "    \n",
    "    return response if confidence >= confidence_threshold else f\"{get_threshold_response()}\\n\\n{response}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LLAMA RESPONSE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anandhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not entirely confident about this answer. Would you like to rephrase or ask about another topic?\n",
      "\n",
      "Telemachus is the son of Odysseus and Penelope in Homer's Odyssey. He is the main character in the first four books of the Odyssey, where he sets out on a journey to find news of his father and to establish his own identity as a hero.\n",
      "\n",
      "Confidence: 1%\n",
      "Sources: Pages 96, 282, 195\n"
     ]
    }
   ],
   "source": [
    "# print(ask_question(\"Who is Telemachus?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anandhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemachus' relationship with Odysseus is central to the Odyssey. When the epic begins, Telemachus is a young man, around 20 years old, who has never known his father, as Odysseus has been away for 20 years fighting in the Trojan War. Telemachus is initially portrayed as timid and inexperienced, but he grows in courage and confidence throughout the story. He sets out on a journey to find news of his father and to establish his own identity as a hero. When Odysseus finally returns to Ithaca, he is initially disguised as a beggar, and Telemachus does not recognize him. However, they eventually reunite, and Odysseus reveals his true identity to Telemachus. Their relationship is one of love, respect, and mutual understanding, as they work together to reclaim their kingdom from the suitors who have been pursuing Penelope.\n",
      "\n",
      "Confidence: 98%\n",
      "Sources: Pages 281, 292, 260\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"And what about his relationship with Odysseus?\"))\n",
    "\n",
    "\n",
    "\n",
    "# BEFORE USING THE SPLIT FUNCTION TO RETURN THE ANSWER\n",
    "# Human: You are a helpful AI assistant. Answer the user's question based on the conversation history and the provided Odyssey context. \n",
    "\n",
    "#     ### Chat History:\n",
    "#     [HumanMessage(content='Who is Telemachus?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Human: You are a helpful AI assistant. Answer the user's question based on the conversation history and the provided Odyssey context. \\n\\n    ### Chat History:\\n    []\\n\\n    ### Context:\\n    Page 282: Who has set my bed otherwhere?\\n\\nPage 96: Who gave thee this raiment?\\n\\nPage 195: Howbeit, Olympian Zeus, that dwells in the clear sky, knows hereof, whether or no he will fulfill for them the evil day before their marriage.” Now even as he spake, a bird flew out on the right, a hawk, the swift messenger of Apollo.\\n\\n    ### Question: \\n    Who is Telemachus?\\n\\n    ### Answer:\\n    Respond in complete sentences and cite text evidence. If unsure, say so.\\n     Telemachus is the son of Odysseus and Penelope.\", additional_kwargs={}, response_metadata={})]\n",
    "\n",
    "#     ### Context:\n",
    "#     Page 292: Then he communed with his heart and soul, whether he should fall on his father’s neck and kiss him, and tell him all, how he had returned and come to his own country, or whether he should first question him and prove him in every word.\n",
    "\n",
    "# Page 260: Would ye stand on the side of the wooers or of Odysseus?\n",
    "\n",
    "# Page 281: Meanwhile, the house-dame Eurynome had bathed the great-hearted Odysseus within his house, and anointed him with olive-oil, and cast about him a goodly mantle and a doublet.\n",
    "\n",
    "#     ### Question: \n",
    "#     And what about his relationship with Odysseus?\n",
    "\n",
    "#     ### Answer:\n",
    "#      Telemachus is the son of Odysseus and Penelope.\n",
    "\n",
    "# Confidence: 98%\n",
    "# Sources: Pages 281, 292, 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anandhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not entirely confident about this answer. Would you like to rephrase or ask about another topic?\n",
      "\n",
      "No, Odysseus did not use a lightsaber. Lightsabers are a fictional weapon from the Star Wars universe, while Odysseus is a character from Homer's Odyssey, set in ancient Greece. The context provided includes descriptions of Odysseus' shield, helmet, and spear, but no mention of a lightsaber.\n",
      "\n",
      "Confidence: 37%\n",
      "Sources: Pages 268, 12\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"Did Odysseus use a lightsaber?\"))\n",
    "\n",
    "\n",
    "# I'm not entirely confident about this answer. Would you like to rephrase or ask about another topic?\n",
    "\n",
    "# Human: You are a helpful AI assistant. Answer the user's question based on the conversation history and the provided Odyssey context. \n",
    "\n",
    "#     ### Chat History:\n",
    "#     [HumanMessage(content='Who is Telemachus?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Human: You are a helpful AI assistant. Answer the user's question based on the conversation history and the provided Odyssey context. \\n\\n    ### Chat History:\\n    []\\n\\n    ### Context:\\n    Page 282: Who has set my bed otherwhere?\\n\\nPage 96: Who gave thee this raiment?\\n\\nPage 195: Howbeit, Olympian Zeus, that dwells in the clear sky, knows hereof, whether or no he will fulfill for them the evil day before their marriage.” Now even as he spake, a bird flew out on the right, a hawk, the swift messenger of Apollo.\\n\\n    ### Question: \\n    Who is Telemachus?\\n\\n    ### Answer:\\n    Respond in complete sentences and cite text evidence. If unsure, say so.\\n     Telemachus is the son of Odysseus and Penelope.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='And what about his relationship with Odysseus?', additional_kwargs={}, response_metadata={}), AIMessage(content='Human: You are a helpful AI assistant. Answer the user\\'s question based on the conversation history and the provided Odyssey context. \\n\\n    ### Chat History:\\n    [HumanMessage(content=\\'Who is Telemachus?\\', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Human: You are a helpful AI assistant. Answer the user\\'s question based on the conversation history and the provided Odyssey context. \\\\n\\\\n    ### Chat History:\\\\n    []\\\\n\\\\n    ### Context:\\\\n    Page 282: Who has set my bed otherwhere?\\\\n\\\\nPage 96: Who gave thee this raiment?\\\\n\\\\nPage 195: Howbeit, Olympian Zeus, that dwells in the clear sky, knows hereof, whether or no he will fulfill for them the evil day before their marriage.” Now even as he spake, a bird flew out on the right, a hawk, the swift messenger of Apollo.\\\\n\\\\n    ### Question: \\\\n    Who is Telemachus?\\\\n\\\\n    ### Answer:\\\\n    Respond in complete sentences and cite text evidence. If unsure, say so.\\\\n     Telemachus is the son of Odysseus and Penelope.\", additional_kwargs={}, response_metadata={})]\\n\\n    ### Context:\\n    Page 292: Then he communed with his heart and soul, whether he should fall on his father’s neck and kiss him, and tell him all, how he had returned and come to his own country, or whether he should first question him and prove him in every word.\\n\\nPage 260: Would ye stand on the side of the wooers or of Odysseus?\\n\\nPage 281: Meanwhile, the house-dame Eurynome had bathed the great-hearted Odysseus within his house, and anointed him with olive-oil, and cast about him a goodly mantle and a doublet.\\n\\n    ### Question: \\n    And what about his relationship with Odysseus?\\n\\n    ### Answer:\\n    Respond in complete sentences and cite text evidence. If unsure, say so.\\n     Telemachus is the son of Odysseus and Penelope.', additional_kwargs={}, response_metadata={})]\n",
    "\n",
    "#     ### Context:\n",
    "#     Page 268: Thence he took out four shields and eight spears, and four helmets of bronze, with thick plumes of horse hair, and he started to bring them and came quickly to his father.\n",
    "\n",
    "# Page 12: Odysseus was the King of Ithaca, a small and rugged island on the western coast of Greece.\n",
    "\n",
    "# Page 268: As for him he girt his fourfold shield about his shoulders and bound on his mighty head a well wrought helmet, with horse hair crest, and terribly the plume waved aloft.\n",
    "\n",
    "#     ### Question: \n",
    "#     Did Odysseus use a lightsaber?\n",
    "\n",
    "#     ### Answer:\n",
    "#      No, Odysseus did not use a lightsaber. The Odyssey describes Odysseus as using a spear, shield, and helmet, but there is no mention of a lightsaber (Page 268: \"four shields and eight spears, and four helmets of bronze\").\n",
    "\n",
    "# Confidence: 37%\n",
    "# Sources: Pages 268, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DEEPSEEK RESPONSE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anandhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not entirely confident about this answer. Would you like to rephrase or ask about another topic?\n",
      "\n",
      "Telemachus is the son of Odysseus and Penelope in Homer's Odyssey. He is the main character in the first four books of the Odyssey, where he sets out on a journey to find news of his father and to establish his own identity as a hero.\n",
      "\n",
      "Confidence: 1%\n",
      "Sources: Pages 96, 282, 195\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"Who is Telemachus?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anandhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemachus' relationship with Odysseus is central to the Odyssey. When the epic begins, Telemachus is a young man, around 20 years old, who has never known his father, as Odysseus has been away for 20 years fighting in the Trojan War. Telemachus is initially portrayed as timid and inexperienced, but he grows in courage and confidence throughout the story. He sets out on a journey to find news of his father and to establish his own identity as a hero. When Odysseus finally returns to Ithaca, he is initially disguised as a beggar, and Telemachus does not recognize him. However, they eventually reunite, and Odysseus reveals his true identity to Telemachus. Their relationship is one of love, respect, and mutual understanding, as they work together to reclaim their kingdom from the suitors who have been pursuing Penelope.\n",
      "\n",
      "Confidence: 98%\n",
      "Sources: Pages 281, 292, 260\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"And what about his relationship with Odysseus?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anandhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not entirely confident about this answer. Would you like to rephrase or ask about another topic?\n",
      "\n",
      "No, Odysseus did not use a lightsaber. Lightsabers are a fictional weapon from the Star Wars universe, while Odysseus is a character from Homer's Odyssey, set in ancient Greece. The context provided includes descriptions of Odysseus' shield, helmet, and spear, but no mention of a lightsaber.\n",
      "\n",
      "Confidence: 37%\n",
      "Sources: Pages 268, 12\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"Did Odysseus use a lightsaber?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
